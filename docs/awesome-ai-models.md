# Awesome AI Models üß†

_Last updated: 2026-01-21 16:00 UTC_

> A curated list of the most capable Large Language Models (LLMs), Small Language Models (SLMs), and specialized AI models available today.

## üèÜ Frontier Models (State-of-the-Art)

| Model | Company | Release | Context | Key Features | License | Status |
|-------|---------|---------|---------|--------------|---------|--------|
| **DeepSeek-V4** | DeepSeek | Jan 2026 | 128K | Reasoning Core, DSA, Interleaved Thinking | MIT | ‚úÖ Active |
| **Qwen3-Max-Thinking** | Alibaba | Jan 2026 | 128K | 100% AIME25/HMMT, parallel computation | Apache 2.0 | ‚úÖ Active |
| **Gemini 3 Pro** | Google | Nov 18, 2025 | 1M+ | PhD-level reasoning, agentic tool-use | Proprietary | ‚úÖ Active |
| **Gemini 3 Flash** | Google | Dec 17, 2025 | 10M | Pro-grade reasoning, Flash speed | Proprietary | ‚úÖ Active |
| **GPT-5.2-Codex** | OpenAI | Dec 18, 2025 | 400K | Cybersecurity, long-horizon refactoring | Proprietary | ‚úÖ Active |
| **GPT-5.2** | OpenAI | Dec 11, 2025 | 400K | Thinking & Instant variants, $1.75/1M | Proprietary | ‚úÖ Active |
| **GPT-5 mini** | OpenAI | Dec 2025 | 128K | Cheap reasoning, $0.25/1M | Proprietary | ‚úÖ Active |
| **Mistral Large 3** | Mistral AI | Dec 2, 2025 | 128K | 675B params, MoE, Open-weight | Apache 2.0 | ‚úÖ Active |
| **Claude Opus 4.5** | Anthropic | Nov 24, 2025 | 200K | Leading reasoning accuracy, effort param | Proprietary | ‚úÖ Active |
| **Llama 4 Scout** | Meta | Dec 2025 | 10M | Open-weight context king | Community | ‚úÖ Active |
| **DeepSeek-V3.2-Speciale** | DeepSeek | Dec 2025 | 128K | Maxed-out reasoning, IMO gold | MIT | ‚úÖ Active |

## üß† Advanced Reasoning Models (2024-2025)

### Qwen3-Max-Thinking
- **Developer**: Alibaba
- **Performance**: 100% accuracy on AIME25 and HMMT benchmarks
- **Status**: In training, not yet publicly released
- **Capabilities**: Unprecedented mathematical reasoning power
- **Significance**: Saturates difficult math benchmarks
- **Expected Release**: 2025

### Gemini 3 Pro
- **Developer**: Google DeepMind
- **Capabilities**: State-of-the-art reasoning with depth and nuance
- **Features**: Exceptional instruction following, tool use, agentic coding
- **Access**: Google AI Studio, Vertex AI, Antigravity platform
- **Multimodal**: Text, images, video, audio, code
- **Status**: Available (2024-2025)

### GPT-5 Series
- **Developer**: OpenAI
- **Variants**: GPT-5, GPT-5.1, GPT-5.2, GPT-5.2-Codex
- **Capabilities**: Smartest, fastest, most useful model with thinking built-in
- **Performance**: Significant leap in intelligence over previous models
- **Features**: State-of-the-art across coding, math, writing, health, visual perception
- **Status**: Available to everyone

### Granite 4.0
- **Developer**: IBM
- **Architecture**: Hybrid Mamba-2/transformer with MoE strategy
- **Efficiency**: 70% lower memory, 2x faster inference
- **Models**: Micro, Tiny, Small variants
- **Focus**: Enterprise efficiency and performance
- **Status**: Released October 2025

## üîì Open-Source / Open-Weight Models

### üè¢ Enterprise / General Purpose
- **Llama 4 (Scout/Maverick)** (Meta)
    - *Specs*: 10M Token Context (Scout), 400B (Maverick)
    - *License*: Meta Community License
    - *Note*: Native multimodal, 10M context standard for RAG.
- **GLM-4.7** (Zhipu AI)
    - *Specs*: 400B+ MoE, Enterprise focus
    - *License*: Open-weight
    - *Note*: Launched Dec 2025. Enhanced multilingual and tool-use.
    - *Status*: ‚úÖ Active
- **Mistral Large 3** (Mistral AI)
    - *Specs*: 675B (MoE)
    - *License*: Apache 2.0
    - *Note*: Released Dec 2, 2025. Top-tier open model.
    - *Status*: ‚úÖ Active
- **Qwen 3 (Max/Next/Thinking)** (Alibaba)
    - *Specs*: 1T+ (Max), Integrated Code Interpreter
    - *License*: Apache 2.0 (Next), API (Max)
    - *Note*: First Chinese model with 100% AIME25 score.
    - *Status*: ‚úÖ Active

### üíª Coding Specialized
- **GPT-5.2-Codex** (OpenAI)
    - *Release*: Dec 18, 2025
    - *Focus*: Cybersecurity, long-horizon refactoring, Windows compatibility.
    - *Status*: ‚úÖ Active
- **DeepSeek-Coder-V2** (DeepSeek)
    - *License*: MIT
    - *Focus*: 236B params, MoE, beats GPT-4 Turbo in coding.
    - *Status*: ‚úÖ Active
- **Qwen3-Coder** (Alibaba)
    - *License*: Apache 2.0
    - *Focus*: 480B params, autonomous dev capabilities.
    - *Status*: ‚úÖ Active
- **Nemotron 3 Nano** (NVIDIA)
    - *Release*: Dec 2025
    - *Specs*: 1M context, high accuracy in coding/math.
    - *Status*: ‚úÖ Active

## üß™ Experimental & Reasoning
- **Gemini 3 Deep Research** (Google)
    - *Focus*: Autonomous multi-step research and synthesis.
    - *Status*: ‚úÖ Active
- **o1 / o3** (OpenAI)
    - *Focus*: Chain-of-thought reasoning ("System 2" thinking).
    - *Status*: ‚úÖ Active
- **DeepSeek-R1** (DeepSeek)
    - *Focus*: Pure RL-based reasoning model.
    - *Status*: ‚úÖ Active
- **DeepSeek-V4** (DeepSeek) üÜï
    - *Release*: Jan 2026
    - *Focus*: Reasoning Core architecture, Dynamic Sparse Attention, Interleaved Thinking.
    - *Status*: ‚úÖ Active
- **Qwen3-Max-Thinking** (Alibaba) üÜï
    - *Release*: Jan 2026
    - *Focus*: Parallel test-time computation, math/coding benchmarks.
    - *Status*: ‚úÖ Active

## üìâ Legacy / Superseded (Reference Only)
- *GPT-4o / GPT-4 Turbo* (Superseded by GPT-5 series)
- *Claude 3.5 Sonnet* (Superseded by 4.5)
- *Llama 3.1* (Superseded by Llama 4)
- *Mistral Large 2* (Superseded by Large 3)
